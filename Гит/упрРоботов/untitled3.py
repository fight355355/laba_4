# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bRDh80nGkN856CMRnXGMvNizt4MhKNUZ
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

x, y = make_blobs(500, 3, centers=4, random_state=2, cluster_std=1.0)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2, stratify=y)
print(f'''Обучающий набор:
Размерность массива признаков: {x_train.shape}
Размерность целевых признаков: {y_train.shape}
Уникальные метки классов: {np.unique(y_train)}

Тестовый набор:
Размерность массива признаков: {x_test.shape}
Размерность целевых признаков: {y_test.shape}
Уникальные метки классов: {np.unique(y_test)}''')

standard_scaler = StandardScaler()

standard_scaler.fit(x_train)

x_train_scaled = standard_scaler.transform(x_train)
x_test_scaled = standard_scaler.transform(x_test)

logistic_regression = LogisticRegression(C=1000.0, random_state=2)
logistic_regression.fit(x_train_scaled, y_train)

y_pred_log_reg = logistic_regression.predict(x_test_scaled)
y_pred_train_log_reg = logistic_regression.predict(x_train_scaled)
mean_mistakes_log_reg = ((y_test!=y_pred_log_reg).sum() + (y_train!=y_pred_train_log_reg).sum())/2

# Принадлежности к различным классам образцов 10, 20, 100:
# Так как нумерация начинается с 0, то 10-ый образец - это 9 по индексы,
# 20 - 19 по индексу и 100 - 99 по индексу
proba_10 = logistic_regression.predict_proba(x_test_scaled[9, :].reshape(1, -1))
proba_20 = logistic_regression.predict_proba(x_test_scaled[19, :].reshape(1, -1))
proba_100 = logistic_regression.predict_proba(x_test_scaled[99, :].reshape(1, -1))

print(f'''Число неверно классифицированных образов: {(y_test!=y_pred_log_reg).sum()}''')
print(f'''Верность классификации: {accuracy_score(y_test, y_pred_log_reg)}''')
print(f'''Вероятность принадлежности к различным классам образца 10 тестовой выборки: {proba_10}''')
print(f'''Вероятность принадлежности к различным классам образца 20 тестовой выборки: {proba_20}''')
print(f'''Вероятность принадлежности к различным классам образца 100 тестовой выборки: {proba_100}''')

colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')
markers = ('s', 'x', 'o', '^', 'v')

fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(5,15))

for i in range(y_test.shape[0]):
    if y_test[i] != y_pred_log_reg[i]:
        ax[0].scatter(x_test[i,0], x_test[i,1], c='white', alpha=1.0, edgecolor='black', linewidth=1, marker='o', s=120)
        ax[1].scatter(x_test[i,1], x_test[i,2], c='white', alpha=1.0, edgecolor='black', linewidth=1, marker='o', s=120)
        ax[2].scatter(x_test[i,2], x_test[i,0], c='white', alpha=1.0, edgecolor='black', linewidth=1, marker='o', s=120)

    ax[0].scatter(x_test[i,0], x_test[i,1], color = colors[y[i]], marker=markers[y[i]])
    ax[1].scatter(x_test[i,1], x_test[i,2], color = colors[y[i]], marker=markers[y[i]])
    ax[2].scatter(x_test[i,2], x_test[i,0], color = colors[y[i]], marker=markers[y[i]])

ax[0].set_xlabel('x[i, 0]')
ax[1].set_xlabel('x[i, 1]')
ax[2].set_xlabel('x[i, 2]')

ax[0].set_ylabel('x[i, 1]')
ax[1].set_ylabel('x[i, 2]')
ax[2].set_ylabel('x[i, 0]')
plt.show()

