# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PhiQvPJ5BflaivsPAZOsjzoahfnjeFXr
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Perceptron, LogisticRegression
from sklearn.metrics import accuracy_score
from matplotlib.colors import ListedColormap
from sklearn.svm import SVC

x, y = make_blobs(500, 2,  centers=2, random_state=3, cluster_std=2.8)

plt.scatter(x[y==1, 0], x[y==1, 1], color='red', marker='o', label='Класс 1')
plt.scatter(x[y==0, 0], x[y==0, 1], color='blue', marker='x', label='Класс 0')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.show()

print(f'''Размерность массива признаков: {x.shape}
Размерность целевых признаков: {y.shape}
Уникальные метки классов: {np.unique(y)}''')

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=13, stratify=y)
print(f'''Обучающий набор:
Размерность массива признаков: {x_train.shape}
Размерность целевых признаков: {y_train.shape}

Тестовый набор:
Размерность массива признаков: {x_test.shape}
Размерность целевых признаков: {y_test.shape}''')

standard_scaler = StandardScaler()

standard_scaler.fit(x_train)

x_train_scaled = standard_scaler.transform(x_train)
x_test_scaled = standard_scaler.transform(x_test)

perceptron = Perceptron(max_iter=40, eta0=0.1, random_state=0)
perceptron.fit(x_train_scaled, y_train)

logistic_regression = LogisticRegression(C=1000.0, random_state=0)
logistic_regression.fit(x_train_scaled, y_train)

svc = SVC(kernel='linear', C=1.0, random_state=0)
svc.fit(x_train_scaled, y_train)

y_pred_perceptron = perceptron.predict(x_test_scaled)
y_pred_train_perceptron = perceptron.predict(x_train_scaled)
mean_mistakes_perceptron = ((y_test!=y_pred_perceptron).sum() + (y_train!=y_pred_train_perceptron).sum())/2

print(f'''Число неверно классифицированных образов: {(y_test!=y_pred_perceptron).sum()}''')
print(f'''Срднее количество ошибочных классификаций на тренировочных и тестовых данных: {mean_mistakes_perceptron}''')
print(f'''Верность классификации: {accuracy_score(y_test, y_pred_perceptron)}''')

y_pred_log_reg = logistic_regression.predict(x_test_scaled)
y_pred_train_log_reg = logistic_regression.predict(x_train_scaled)
mean_mistakes_log_reg = ((y_test!=y_pred_log_reg).sum() + (y_train!=y_pred_train_log_reg).sum())/2

# Принадлежности к различным классам образцов 10, 20, 100:
# Так как нумерация начинается с 0, то 10-ый образец - это 9 по индексы,
# 20 - 19 по индексу и 100 - 99 по индексу
proba_10 = logistic_regression.predict_proba(x_test_scaled[9, :].reshape(1, -1))
proba_20 = logistic_regression.predict_proba(x_test_scaled[19, :].reshape(1, -1))
proba_100 = logistic_regression.predict_proba(x_test_scaled[99, :].reshape(1, -1))

print(f'''Число неверно классифицированных образов: {(y_test!=y_pred_log_reg).sum()}''')
print(f'''Срднее количество ошибочных классификаций на тренировочных и тестовых данных: {mean_mistakes_log_reg}''')
print(f'''Верность классификации: {accuracy_score(y_test, y_pred_log_reg)}''')
print(f'''Вероятность принадлежности к различным классам образца 10 тестовой выборки: {proba_10}''')
print(f'''Вероятность принадлежности к различным классам образца 20 тестовой выборки: {proba_20}''')
print(f'''Вероятность принадлежности к различным классам образца 100 тестовой выборки: {proba_100}''')

y_pred_svc = svc.predict(x_test_scaled)
y_pred_train_svc = svc.predict(x_train_scaled)
mean_mistakes_svc = ((y_test!=y_pred_svc).sum() + (y_train!=y_pred_train_svc).sum())/2

print(f'''Число неверно классифицированных образов: {(y_test!=y_pred_svc).sum()}''')
print(f'''Срднее количество ошибочных классификаций на тренировочных и тестовых данных: {mean_mistakes_svc}''')
print(f'''Верность классификации: {accuracy_score(y_test, y_pred_svc)}''')

def plotDecisionRegions(x, y, classifier, resolution=0.02, test_idx=None):
    markers = ('s', 'x', 'o', '^', 'v')
    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')
    cmap = ListedColormap(colors[:len(np.unique(y))])

    x1_min, x1_max = x[:,0].min() - 1, x[:,0].max() + 1
    x2_min, x2_max = x[:,1].min() - 1, x[:,1].max() + 1
    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),
                           np.arange(x2_min, x2_max, resolution))

    z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)
    z = z.reshape(xx1.shape)

    plt.contourf(xx1, xx2, z, alpha=0.4, cmap=cmap)
    plt.xlim(xx1.min(), xx1.max())
    plt.ylim(xx2.min(), xx2.max())

    for idx, cl in enumerate(np.unique(y)):
        plt.scatter(x=x[y==cl, 0], y=x[y==cl, 1], alpha=0.8, c=colors[idx],
                    edgecolor='black', marker = markers[idx], label=cl)
        if test_idx:
            x_test = x[test_idx, :]
            plt.scatter(x_test[:, 0], x_test[:, 1], c='', alpha=1.0,
                        edgecolor='black', linewidths=1, marker='o', s=120,
                        label='test set')

plotDecisionRegions(x_test_scaled, y_test, perceptron)
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.title('Perceptron')
plt.show()

plotDecisionRegions(x_test_scaled, y_test, logistic_regression)
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.title('Logistic regression')
plt.show()

plotDecisionRegions(x_test_scaled, y_test, svc)
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.title('Support vector machines')
plt.show()